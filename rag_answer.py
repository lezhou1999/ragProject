from retriever import retrieve_chunks
from transformers import pipeline
from openai import OpenAI
from dotenv import load_dotenv
import os
# How to get the firmware version of a dimmer?
# åˆå§‹åŒ–æœ¬åœ°æˆ– OpenAI QA æ¨¡å‹ï¼ˆæ ¹æ®ä½ æƒ³è¦çš„æ–¹å¼ï¼‰
#qa_pipeline = pipeline("question-answering", model="deepset/roberta-base-squad2")

load_dotenv()

# è·å– API key

#print("API Key loaded:", os.getenv("OPENAI_API_KEY"))
api_key = os.getenv("OPENAI_API_KEY")

client = OpenAI(api_key=api_key)


def answer_query(query: str):
    '''
    chunks = retrieve_chunks(query, top_k=3)
    context = "\n\n".join([chunk[0] for chunk in chunks])
   
    result = qa_pipeline({
        "question": query,
        "context": context
    })
    return result["answer"]
    '''
    results = retrieve_chunks(query)
    chunks = [chunk for chunk, _ in results]   # å–å‡º chunkï¼ˆä¸¢æ‰ scoreï¼‰


    # Step 2: æ‹¼æ¥ä¸Šä¸‹æ–‡
    # å¦‚æœ chunks æ˜¯ dictï¼Œå°±å– contentï¼›å¦‚æœæ˜¯ strï¼Œç›´æ¥ç”¨
    context = "\n\n".join([c["content"] if isinstance(c, dict) else str(c) for c in chunks])


    # Step 3: æ„é€  Prompt
    prompt = f"""
You are an assistant with access to YoSmart device API documentation.
Use the following context to answer the question as accurately as possible.
If the answer is not in the context, say "I don't know from docs."


Question: {query}


Context:
{context}


Answer:
"""


    # Step 4: è°ƒç”¨ OpenAI GPT
    response = client.chat.completions.create(
        model="gpt-4o-mini",   # âœ… æˆæœ¬ä½ï¼Œä¹Ÿè¶³å¤Ÿå¼º
        messages=[
            {"role": "system", "content": "You are a helpful assistant for YoSmart API documentation."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.0
    )


    return response.choices[0].message.content.strip()




if __name__ == "__main__":
    query = input(" Your Question: ")
    print("ğŸ§¾ Answer:", answer_query(query))
